task_name: ${task.name}
experiment: AT_act_2.0
num_envs: ''
seed: 42
torch_deterministic: false
max_iterations: ''
physics_engine: physx
pipeline: gpu
sim_device: gpu
device_id: 0
rl_device: cuda:0
multi_gpu: false
num_threads: 4
solver_type: 1
test: false
checkpoint: ''
evaluation: false
headless: true
enable_livestream: false
mt_timeout: 90
wandb_activate: false
wandb_group: ''
wandb_name: ${train.params.config.name}
wandb_entity: ''
wandb_project: omniisaacgymenvs
kit_app: ''
warp: false
task:
  name: AliengoTerrain
  physics_engine: ${..physics_engine}
  env:
    numEnvs: ${resolve_default:4096,${...num_envs}}
    numObservations: 188
    numActions: 12
    envSpacing: 3.0
    terrain:
      staticFriction: 1.0
      dynamicFriction: 1.0
      restitution: 0.0
      curriculum: true
      maxInitMapLevel: 0
      mapLength: 8.0
      mapWidth: 8.0
      numLevels: 10
      numTerrains: 20
      terrainProportions:
      - 0.1
      - 0.1
      - 0.35
      - 0.25
      - 0.2
      slopeTreshold: 0.75
    baseInitState:
      pos:
      - 0.0
      - 0.0
      - 0.55
      rot:
      - 1.0
      - 0.0
      - 0.0
      - 0.0
      vLinear:
      - 0.0
      - 0.0
      - 0.0
      vAngular:
      - 0.0
      - 0.0
      - 0.0
    randomCommandVelocityRanges:
      linear_x:
      - -1.0
      - 1.0
      linear_y:
      - -1.0
      - 1.0
      yaw:
      - -3.14
      - 3.14
    control:
      stiffness: 40.0
      damping: 2.0
      actionScale: 2.5
      decimation: 4
    defaultJointAngles:
      FR_hip_joint: 0.0
      FR_thigh_joint: 0.8
      FR_calf_joint: -1.5
      FL_hip_joint: 0.0
      FL_thigh_joint: 0.8
      FL_calf_joint: -1.5
      RR_hip_joint: 0.0
      RR_thigh_joint: 0.8
      RR_calf_joint: -1.5
      RL_hip_joint: 0.0
      RL_thigh_joint: 0.8
      RL_calf_joint: -1.5
    learn:
      terminalReward: 0.0
      linearVelocityXYRewardScale: 1.0
      linearVelocityZRewardScale: -2.0
      angularVelocityXYRewardScale: -0.05
      angularVelocityZRewardScale: 0.5
      orientationRewardScale: -0.2
      torqueRewardScale: -0.0
      jointAccRewardScale: -2.5e-07
      baseHeightRewardScale: -1.0
      actionRateRewardScale: -0.01
      fallenOverRewardScale: -1.0
      footClearanceRewardScale: -0.01
      jointPowerRewardScale: -2.0e-05
      smoothnessRewardScale: -0.01
      powerDistributionRewardScale: -1.0e-05
      hipRewardScale: -0.0
      linearVelocityScale: 2.0
      angularVelocityScale: 0.25
      dofPositionScale: 1.0
      dofVelocityScale: 0.05
      heightMeasurementScale: 5.0
      addNoise: true
      noiseLevel: 1.0
      dofPositionNoise: 0.01
      dofVelocityNoise: 1.5
      linearVelocityNoise: 0.1
      angularVelocityNoise: 0.2
      gravityNoise: 0.05
      heightMeasurementNoise: 0.1
      pushInterval_s: 15
      episodeLength_s: 20
  sim:
    dt: 0.005
    use_gpu_pipeline: ${eq:${...pipeline},"gpu"}
    gravity:
    - 0.0
    - 0.0
    - -9.81
    add_ground_plane: false
    add_distant_light: false
    use_fabric: true
    enable_scene_query_support: false
    disable_contact_processing: true
    enable_cameras: false
    default_physics_material:
      static_friction: 1.0
      dynamic_friction: 1.0
      restitution: 0.0
    physx:
      worker_thread_count: ${....num_threads}
      solver_type: ${....solver_type}
      use_gpu: ${eq:${....sim_device},"gpu"}
      solver_position_iteration_count: 4
      solver_velocity_iteration_count: 0
      contact_offset: 0.01
      rest_offset: 0.0
      bounce_threshold_velocity: 0.5
      friction_offset_threshold: 0.04
      friction_correlation_distance: 0.025
      enable_sleeping: true
      enable_stabilization: true
      max_depenetration_velocity: 1.0
      gpu_max_rigid_contact_count: 524288
      gpu_max_rigid_patch_count: 163840
      gpu_found_lost_pairs_capacity: 200000000
      gpu_found_lost_aggregate_pairs_capacity: 50000000
      gpu_total_aggregate_pairs_capacity: 200000000
      gpu_max_soft_body_contacts: 1048576
      gpu_max_particle_contacts: 1048576
      gpu_heap_capacity: 134217728
      gpu_temp_buffer_capacity: 33554432
      gpu_max_num_partitions: 8
    aliengo:
      override_usd_defaults: false
      enable_self_collisions: true
      enable_gyroscopic_forces: false
      solver_position_iteration_count: 4
      solver_velocity_iteration_count: 0
      sleep_threshold: 0.005
      stabilization_threshold: 0.001
      density: -1
      max_depenetration_velocity: 1.0
train:
  params:
    seed: ${...seed}
    algo:
      name: a2c_continuous
    model:
      name: continuous_a2c_logstd
    network:
      name: actor_critic
      separate: true
      space:
        continuous:
          mu_activation: None
          sigma_activation: None
          mu_init:
            name: default
          sigma_init:
            name: const_initializer
            val: 0.0
          fixed_sigma: true
      mlp:
        units:
        - 512
        - 256
        - 128
        activation: elu
        d2rl: false
        initializer:
          name: default
        regularizer:
          name: None
    load_checkpoint: ${if:${...checkpoint},True,False}
    load_path: ${...checkpoint}
    config:
      name: ${resolve_default:AliengoTerrain,${....experiment}}
      full_experiment_name: ${.name}
      device: ${....rl_device}
      device_name: ${....rl_device}
      env_name: rlgpu
      multi_gpu: ${....multi_gpu}
      ppo: true
      mixed_precision: false
      normalize_input: true
      normalize_value: true
      normalize_advantage: true
      value_bootstrap: true
      clip_actions: false
      num_actors: ${....task.env.numEnvs}
      reward_shaper:
        scale_value: 1.0
      gamma: 0.99
      tau: 0.95
      e_clip: 0.2
      entropy_coef: 0.01
      learning_rate: 0.001
      lr_schedule: adaptive
      kl_threshold: 0.01
      truncate_grads: true
      grad_norm: 1.0
      horizon_length: 200
      minibatch_size: 32768
      mini_epochs: 5
      critic_coef: 1.0
      clip_value: true
      seq_length: 4
      bounds_loss_coef: 0.0
      max_epochs: ${resolve_default:2000,${....max_iterations}}
      save_best_after: 50
      score_to_win: 20000
      save_frequency: 50
      print_stats: true
